{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8210b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d8261",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsDataset(Dataset):\n",
    "    def __init__(self, jsonl_path: str | Path, transform=None, class_to_idx: dict[str, int] | None = None):\n",
    "        self.jsonl_path = Path(jsonl_path)\n",
    "        self.transform = transform\n",
    "        with self.jsonl_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            self.items = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "        if class_to_idx is None:\n",
    "            classes = sorted({item[\"class_name\"] for item in self.items})\n",
    "            self.class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "        else:\n",
    "            self.class_to_idx = dict(class_to_idx)\n",
    "\n",
    "        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.items[idx]\n",
    "        image = Image.open(item[\"image\"]).convert(\"RGB\")\n",
    "        label = self.class_to_idx[item[\"class_name\"]]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b471fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 160\n",
    "batch_size = 16\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomResizedCrop(image_size),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "eval_transform = T.Compose([\n",
    "    T.Resize(int(image_size * 1.14)),\n",
    "    T.CenterCrop(image_size),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "training_data = DogsDataset(\"data/splits/dogs_train.jsonl\", transform=train_transform)\n",
    "val_data = DogsDataset(\"data/splits/dogs_val.jsonl\", transform=eval_transform, class_to_idx=training_data.class_to_idx)\n",
    "test_data = DogsDataset(\"data/splits/dogs_test.jsonl\", transform=eval_transform, class_to_idx=training_data.class_to_idx)\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(\"train/val/test sizes:\", len(training_data), len(val_data), len(test_data))\n",
    "print(\"x:\", x.shape, \"y:\", y.shape, \"num_classes:\", len(training_data.class_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a944b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(training_data.class_to_idx)\n",
    "\n",
    "try:\n",
    "    weights = torchvision.models.ResNet18_Weights.DEFAULT\n",
    "    model = torchvision.models.resnet18(weights=weights)\n",
    "    print(\"Loaded pretrained ResNet18 weights\")\n",
    "except Exception as e:\n",
    "    model = torchvision.models.resnet18(weights=None)\n",
    "    print(\"Could not load pretrained weights; using random init. Error:\", repr(e))\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Model ready. Output classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753cca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_value, current = loss.item(), (batch + 1) * len(X)\n",
    "        print(f\"loss: {loss_value:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0.0, 0.0\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        test_loss += loss_fn(pred, y).item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= max(1, num_batches)\n",
    "    correct /= max(1, size)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return 100 * correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "epochs = 10\n",
    "\n",
    "while True:\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    val_acc = test(val_dataloader, model, loss_fn)\n",
    "    if (epochs != 0 and epoch + 1 >= epochs):\n",
    "        break\n",
    "    epoch += 1\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5addeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = test(test_dataloader, model, loss_fn)\n",
    "print(f\"Test acc {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cddbbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"state_dict\": model.state_dict(), \"class_to_idx\": training_data.class_to_idx}, \"resnet18_dogs_cpu.pth\")\n",
    "print(\"Saved to resnet18_dogs_cpu.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41f4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, sys, subprocess\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ipywidgets\"])\n",
    "    import ipywidgets as widgets\n",
    "\n",
    "idx_to_class = {v: k for k, v in training_data.class_to_idx.items()}\n",
    "model.eval()\n",
    "\n",
    "uploader = widgets.FileUpload(accept=\"image/*\", multiple=False)\n",
    "out = widgets.Output()\n",
    "\n",
    "def _predict_from_bytes(image_bytes: bytes):\n",
    "    img = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "    x = eval_transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        probs = torch.softmax(logits, dim=1)[0]\n",
    "        values, indices = torch.topk(probs, k=min(5, probs.numel()))\n",
    "    return [(idx_to_class[int(i)], float(v)) for v, i in zip(values, indices)]\n",
    "\n",
    "def _get_uploaded_bytes(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, dict):\n",
    "        if not value:\n",
    "            return None\n",
    "        item = next(iter(value.values()))\n",
    "        if isinstance(item, dict):\n",
    "            return item.get(\"content\") or item.get(\"data\")\n",
    "        return getattr(item, \"content\", None)\n",
    "    if isinstance(value, (tuple, list)):\n",
    "        if len(value) == 0:\n",
    "            return None\n",
    "        item = value[0]\n",
    "        if isinstance(item, dict):\n",
    "            return item.get(\"content\") or item.get(\"data\")\n",
    "        return getattr(item, \"content\", None)\n",
    "    return getattr(value, \"content\", None)\n",
    "\n",
    "def _on_upload(change):\n",
    "    out.clear_output()\n",
    "    image_bytes = _get_uploaded_bytes(change.get(\"new\"))\n",
    "    if image_bytes is None:\n",
    "        return\n",
    "    preds = _predict_from_bytes(image_bytes)\n",
    "    with out:\n",
    "        print(\"Top predictions:\")\n",
    "        for cls, p in preds:\n",
    "            print(f\"{cls}: {p*100:.2f}%\")\n",
    "\n",
    "uploader.observe(_on_upload, names=\"value\")\n",
    "display(uploader, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"resnet18_dogs_cpu.pth\")\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "print(\"Model loaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
